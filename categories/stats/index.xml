<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Stats on Ten thousand words...</title><link>https://mespe.github.io/categories/stats/</link><description>Recent content in Stats on Ten thousand words...</description><generator>Hugo -- gohugo.io</generator><lastBuildDate>Wed, 27 Jun 2018 16:16:50 -0600</lastBuildDate><atom:link href="https://mespe.github.io/categories/stats/index.xml" rel="self" type="application/rss+xml"/><item><title>Retrospective Power Analysis</title><link>https://mespe.github.io/post/power/</link><pubDate>Wed, 27 Jun 2018 16:16:50 -0600</pubDate><guid>https://mespe.github.io/post/power/</guid><description>&amp;hellip;Or, can we trust these estimates? One of the most common questions that comes up in scientific publications is &amp;ldquo;Can I trust these conclusions?&amp;rdquo; Statistics is supposed to help us decide the weight of evidence for or against a certain conclusion, but there have been issues. We are realizing that the standard paradim is not holding up, and there are many more false positives in the literature than the p &amp;lt; 0.</description></item><item><title>Moving past p-values</title><link>https://mespe.github.io/post/new_v_old/</link><pubDate>Fri, 30 Jun 2017 19:35:44 -0700</pubDate><guid>https://mespe.github.io/post/new_v_old/</guid><description>I had a marathon review/revision session with my adviser last week regarding a manuscript I am working on - overall took 2 hours!
We were going round and round in circles, and finally 1.25 hours in we got to the piece of my paper that was really bugging my advisor: I did not have a single p-value in the entire paper. What followed was a really interesting exchange that I think highlights some of the issues that are behind scientific research, especially in agriculture, using out-of-date statistics.</description></item></channel></rss>